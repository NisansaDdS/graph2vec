{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyPgBKpmaDC7EZPrCEGdZYsr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"qqVoyQCo-Uji","executionInfo":{"status":"ok","timestamp":1630947028679,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}}},"source":["__author__ = 'porky-chu'\n","\n","import theano\n","import numpy as np\n","from theano import tensor as TT\n","\n","\n","class NodeVectorModel(object):\n","    def __init__(self, n_from, n_to, de, seed=1692, init_params=None):\n","        \"\"\"\n","        n_from :: number of from embeddings in the vocabulary\n","        n_to :: number of to embeddings in the vocabulary\n","        de :: dimension of the word embeddings\n","        \"\"\"\n","        np.random.seed(seed)\n","        # parameters of the model\n","        if init_params is not None:\n","            with open('data/case_embeddings.pkl', 'rb') as f:\n","                temp = cPickle.load(f)\n","            self.Win = theano.shared(temp.Win.get_value().astype(theano.config.floatX))\n","            self.Wout = theano.shared(temp.Wout.get_value().astype(theano.config.floatX))\n","        else:\n","            self.Win = theano.shared(0.2 * np.random.uniform(-1.0, 1.0, (n_from, de)).astype(theano.config.floatX))\n","            self.Wout = theano.shared(0.2 * np.random.uniform(-1.0, 1.0, (n_to, de)).astype(theano.config.floatX))\n","\n","        # adagrad\n","        self.cumulative_gradients_in = theano.shared(0.1 * np.ones((n_from, de)).astype(theano.config.floatX))\n","        self.cumulative_gradients_out = theano.shared(0.1 * np.ones((n_to, de)).astype(theano.config.floatX))\n","\n","        idxs = TT.imatrix()\n","        x_in = self.Win[idxs[:, 0], :]\n","        x_out = self.Wout[idxs[:, 1], :]\n","\n","        norms_in= TT.sqrt(TT.sum(x_in ** 2, axis=1))\n","        norms_out = TT.sqrt(TT.sum(x_out ** 2, axis=1))\n","        norms = norms_in * norms_out\n","\n","        y = TT.vector('y')  # label\n","        y_predictions = TT.sum(x_in * x_out, axis=1) / norms\n","\n","        # cost and gradients and learning rate\n","        loss = TT.mean(TT.sqr(y_predictions - y))\n","        gradients = TT.grad(loss, [x_in, x_out])\n","\n","        updates = [\n","            (self.cumulative_gradients_in, TT.inc_subtensor(self.cumulative_gradients_in[idxs[:, 0]], gradients[0] ** 2)),\n","            (self.cumulative_gradients_out, TT.inc_subtensor(self.cumulative_gradients_out[idxs[:, 1]], gradients[1] ** 2)),\n","            (self.Win, TT.inc_subtensor(self.Win[idxs[:, 0]], - (0.5 / TT.sqrt(self.cumulative_gradients_in[idxs[:, 0]])) * gradients[0])),\n","            (self.Wout, TT.inc_subtensor(self.Wout[idxs[:, 1]], - (0.5 / TT.sqrt(self.cumulative_gradients_out[idxs[:, 1]])) * gradients[1])),\n","        ]\n","\n","        # theano functions\n","        self.calculate_loss = theano.function(inputs=[idxs, y], outputs=loss)\n","        self.classify = theano.function(inputs=[idxs], outputs=y_predictions)\n","        self.train = theano.function(\n","            inputs=[idxs, y],\n","            outputs=loss,\n","            updates=updates,\n","            name='training_fn'\n","        )\n","\n","    def __getstate__(self):\n","        return self.Win, self.Wout\n","\n","    def __setstate__(self, state):\n","        Win, Wout = state\n","        self.Win = Win\n","        self.Wout = Wout\n","\n","    def save_to_file(self, output_path):\n","        with open(output_path, 'wb') as output_file:\n","            #cPickle.dump(self, output_file, cPickle.HIGHEST_PROTOCOL)\n","            print(\"Save\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"feymSZ3U-s4H","executionInfo":{"status":"ok","timestamp":1630947204664,"user_tz":-330,"elapsed":326,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}}},"source":["__author__ = 'allentran'\n","\n","import json\n","import os\n","import multiprocessing\n","\n","import numpy as np\n","\n","def _update_min_dict(candidate_node, depth, min_set):\n","    if candidate_node in min_set:\n","        if min_set[candidate_node] <= depth:\n","            return\n","        else:\n","            min_set[candidate_node] = depth\n","    else:\n","        min_set[candidate_node] = depth\n","\n","def _get_connected_nodes(node_idx, adjancency_list, max_degree, current_depth=1):\n","    connected_dict = {}\n","    single_degree_nodes = [other_idx for other_idx in adjancency_list[node_idx] if adjancency_list[node_idx][other_idx] == 1]\n","    for other_idx in single_degree_nodes:\n","        _update_min_dict(other_idx, current_depth, connected_dict)\n","\n","    if current_depth <= max_degree:\n","        for other_node_idx in single_degree_nodes:\n","            if other_node_idx in adjancency_list:\n","                new_connected_nodes = _get_connected_nodes(other_node_idx, adjancency_list, max_degree, current_depth + 1)\n","                if new_connected_nodes is not None:\n","                    for other_idx, depth in new_connected_nodes.iteritems():\n","                        _update_min_dict(other_idx, depth, connected_dict)\n","        return connected_dict\n","\n","class Graph(object):\n","\n","    def __init__(self, graph_path):\n","\n","        self.from_nodes_mapping = {}\n","        self.to_nodes_mapping = {}\n","\n","        self.edge_dict = {}\n","\n","        self._load_graph(graph_path=graph_path)\n","        self._create_mappings()\n","\n","    def save_mappings(self, output_dir):\n","        print(\"wow\")\n","        return\n","        with open(os.path.join(output_dir, 'from.map'), 'w') as from_map_file:\n","            json.dump(self.from_nodes_mapping, from_map_file)\n","        with open(os.path.join(output_dir, 'to.map'), 'w') as to_map_file:\n","            json.dump(self.to_nodes_mapping, to_map_file)\n","\n","    def get_mappings(self):\n","        return self.from_nodes_mapping, self.to_nodes_mapping\n","\n","    def _create_mappings(self):\n","        for key in self.edge_dict:\n","            self.from_nodes_mapping[key] = len(self.from_nodes_mapping)\n","        for to_nodes in self.edge_dict.values():\n","            for to_node in to_nodes:\n","                if to_node not in self.to_nodes_mapping:\n","                    self.to_nodes_mapping[to_node] = len(self.to_nodes_mapping)\n","\n","    def _add_edge(self, from_idx, to_idx, degree=1):\n","        if from_idx not in self.edge_dict:\n","            self.edge_dict[from_idx] = dict()\n","        if to_idx in self.edge_dict[from_idx]:\n","            if degree >= self.edge_dict[from_idx][to_idx]:\n","                return\n","        self.edge_dict[from_idx][to_idx] = degree\n","\n","    def _load_graph(self, graph_path):\n","\n","        with open(graph_path, 'r') as graph_file:\n","            for line in graph_file:\n","                parsed_line = line.strip().split(' ')\n","                if len(parsed_line) in [2, 3]:\n","                    from_idx = int(parsed_line[0])\n","                    to_idx = int(parsed_line[1])\n","                    if len(parsed_line) == 3:\n","                        degree = int(parsed_line[2])\n","                        self._add_edge(from_idx, to_idx, degree)\n","                    else:\n","                        self._add_edge(from_idx, to_idx)\n","\n","    def extend_graph(self, max_degree, penalty=2):\n","\n","        def _zip_args_for_parallel_fn():\n","            for key in self.from_nodes_mapping.keys():\n","                yield (key, self.edge_dict, max_degree)\n","\n","        from_to_idxs = []\n","        degrees = []\n","\n","        pool = multiprocessing.Pool(multiprocessing.cpu_count())\n","        connected_nodes_list = pool.map(_get_connected_nodes, _zip_args_for_parallel_fn())\n","        pool.close()\n","        pool.join()\n","\n","        for node_idx, connected_nodes in zip(self.from_nodes_mapping.keys(), connected_nodes_list):\n","            for other_node, degree in connected_nodes.iteritems():\n","                from_to_idxs.append([self.from_nodes_mapping[node_idx], self.to_nodes_mapping[other_node]])\n","                degrees.append(float(1)/(degree ** penalty))\n","\n","        return np.array(from_to_idxs).astype(np.int32), np.array(degrees).astype(np.float32)\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilREQ-F_-kYk","executionInfo":{"status":"ok","timestamp":1630947029026,"user_tz":-330,"elapsed":351,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}}},"source":["__author__ = 'porky-chu'\n","\n","import random\n","import os\n","import logging\n","\n","import numpy as np\n","\n","#from node_vectors import NodeVectorModel\n","#import parser\n","\n","\n","class Graph2Vec(object):\n","    def __init__(self, vector_dimensions, output_dir='data'):\n","\n","        self.output_dir = output_dir\n","\n","        self.model = None\n","        self.from_nodes = None\n","        self.to_nodes = None\n","        self.dimensions = vector_dimensions\n","        self.from_to_idxs = None\n","        self.inverse_degrees = None\n","\n","    def parse_graph(self, graph_path, data_dir='data', load_edges=False, extend_paths=2):\n","        graph = Graph(graph_path)\n","        self.from_nodes, self.to_nodes = graph.get_mappings()\n","        graph.save_mappings(self.output_dir)\n","\n","        if load_edges:\n","            self.inverse_degrees = np.memmap(\n","                os.path.join(data_dir, 'inverse_degrees.mat'),\n","                mode='r',\n","                dtype='float32'\n","            )\n","            self.from_to_idxs = np.memmap(\n","                os.path.join(data_dir, 'from_to.mat'),\n","                mode='r',\n","                dtype='int32'\n","            )\n","            self.from_to_idxs = np.reshape(self.from_to_idxs, newshape=(self.inverse_degrees.shape[0], 2))\n","        else:\n","            from_to_idxs, inverse_degrees = graph.extend_graph(max_degree=extend_paths)\n","            self.from_to_idxs = np.memmap(\n","                os.path.join(data_dir, 'from_to.mat'),\n","                mode='r+',\n","                shape=from_to_idxs.shape,\n","                dtype='int32'\n","            )\n","            self.from_to_idxs[:] = from_to_idxs[:]\n","            self.inverse_degrees = np.memmap(\n","                os.path.join(data_dir, 'inverse_degrees.mat'),\n","                mode='r+',\n","                shape=inverse_degrees.shape,\n","                dtype='float32'\n","            )\n","            self.inverse_degrees[:] = inverse_degrees[:]\n","\n","\n","    def fit(self, max_epochs=100, batch_size=1000, seed=1692, params=None):\n","\n","        self.model = NodeVectorModel(\n","            n_from=len(self.from_nodes),\n","            n_to=len(self.to_nodes),\n","            de=self.dimensions,\n","            init_params=params,\n","        )\n","\n","        random.seed(seed)\n","        shuffled_idxes = np.arange(self.from_to_idxs.shape[0])\n","        for epoch_idx in xrange(max_epochs):\n","\n","            random.shuffle(shuffled_idxes)\n","\n","            cost = []\n","            for obs_idx in xrange(0, len(self.inverse_degrees), batch_size):\n","                cost.append(self.model.train(self.from_to_idxs[shuffled_idxes[obs_idx:obs_idx + batch_size]],\n","                                          self.inverse_degrees[shuffled_idxes[obs_idx:obs_idx + batch_size]]))\n","\n","            cost = np.mean(cost)\n","            logging.info('After %s epochs, cost=%s' % (epoch_idx, cost ** 0.5))\n","\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhy0F2Of8RDv","executionInfo":{"status":"ok","timestamp":1630947032814,"user_tz":-330,"elapsed":3792,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}},"outputId":"a18e40b8-72a3-4b2d-8abe-10666432d6c4"},"source":["!pip install graph2vec\n","!pip install pickle"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: graph2vec in /usr/local/lib/python3.7/dist-packages (0.0.2)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94ScQEqx9M1X","executionInfo":{"status":"ok","timestamp":1630947032815,"user_tz":-330,"elapsed":25,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}},"outputId":"d240419a-0108-4bbf-cbd5-058b3f8d63cd"},"source":["import graph2vec \n","\n","help(graph2vec)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package graph2vec:\n","\n","NAME\n","    graph2vec\n","\n","PACKAGE CONTENTS\n","    node_vectors\n","    parser\n","    trainer\n","\n","AUTHOR\n","    porky-chu\n","\n","FILE\n","    /usr/local/lib/python3.7/dist-packages/graph2vec/__init__.py\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xetDcuY6BEVp","executionInfo":{"status":"ok","timestamp":1630947032816,"user_tz":-330,"elapsed":20,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}},"outputId":"5fb08861-3791-46d8-b427-0c82e1b5b002"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":612},"id":"z1BsPP2g7V85","executionInfo":{"status":"error","timestamp":1630947210881,"user_tz":-330,"elapsed":631,"user":{"displayName":"Nisansa de Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3NvZ4zb-ERM3KiNdF2C-Tp6MsT2QphdB5L7FMQ=s64","userId":"09282768075823282303"}},"outputId":"9d91d7e3-530a-4476-9ca5-73bb4c0c1199"},"source":["\n","graph2vec =Graph2Vec(vector_dimensions=128)\n","graph2vec.parse_graph('/content/drive/MyDrive/Research/Sinhala NLP/Graph2Vec/data/edge.data', extend_paths=2)\n","graph2vec.fit(batch_size=1000, max_epochs=1000)\n","node2vec.model.save_to_file(\"/content/drive/MyDrive/Research/Sinhala NLP/Graph2Vec/data/case_embeddings.pkl\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["wow\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)","\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\nTypeError: _get_connected_nodes() missing 2 required positional arguments: 'adjancency_list' and 'max_degree'\n\"\"\"","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-463149a6efc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgraph2vec\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mGraph2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_dimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Research/Sinhala NLP/Graph2Vec/data/edge.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnode2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Research/Sinhala NLP/Graph2Vec/data/case_embeddings.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-6b4a5be8dca2>\u001b[0m in \u001b[0;36mparse_graph\u001b[0;34m(self, graph_path, data_dir, load_edges, extend_paths)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_to_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_to_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_degrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mfrom_to_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_degrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextend_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             self.from_to_idxs = np.memmap(\n\u001b[1;32m     45\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_to.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1a2e82122867>\u001b[0m in \u001b[0;36mextend_graph\u001b[0;34m(self, max_degree, penalty)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mconnected_nodes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_connected_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_zip_args_for_parallel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: _get_connected_nodes() missing 2 required positional arguments: 'adjancency_list' and 'max_degree'"]}]}]}